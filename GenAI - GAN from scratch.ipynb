{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b8cb845b-3c14-4350-b89f-584e36e2dac1",
      "metadata": {
        "id": "b8cb845b-3c14-4350-b89f-584e36e2dac1"
      },
      "source": [
        "## Criação de uma GAN para gerar imagens sintéticas de números manuscritos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c903a890-44d3-416c-aff4-1c9169080102",
      "metadata": {
        "id": "c903a890-44d3-416c-aff4-1c9169080102"
      },
      "source": [
        "Neste estudo irei criar uma Generative Adversarial Network (GAN) básica para tentar criar dados sintéticos de números manuscritos, para isto irei usar a estutura GAN padrão:\n",
        "\n",
        "```\n",
        "            +-------------------+\n",
        "            |   Random Noise z  |   (Entrada do Gerador)\n",
        "            +-------------------+\n",
        "                     |\n",
        "                     v\n",
        "            +-------------------+\n",
        "            |     Generator     |   (Gera dados falsos)\n",
        "            +-------------------+\n",
        "                     |\n",
        "                     v\n",
        "            +-------------------+       +-------------------+\n",
        "            |  Fake Data (G(z)) | ----> |                   |\n",
        "            +-------------------+       |                   |\n",
        "                                        |   Discriminator   | --> Classifica Real/Falso\n",
        "            +-------------------+       |                   |\n",
        "            | Real Data (x)     | ----> |                   |\n",
        "            +-------------------+       +-------------------+\n",
        "                          ^                       ^\n",
        "                          |                       |\n",
        "              (Feedback para Treinamento)    (Feedback para Treinamento)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56bbd4a-974a-41b8-8a26-4d73689d546e",
      "metadata": {
        "id": "a56bbd4a-974a-41b8-8a26-4d73689d546e"
      },
      "source": [
        "### Carregamento de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0069aa9a-90e2-4638-a648-7f9b7c0edcfc",
      "metadata": {
        "id": "0069aa9a-90e2-4638-a648-7f9b7c0edcfc"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow matplotlib numpy > nul 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eca8b8e9-6213-46f5-bd8b-d3f06ff29b15",
      "metadata": {
        "id": "eca8b8e9-6213-46f5-bd8b-d3f06ff29b15"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470b869b-ed05-4808-9acb-48dc6bf5b6ac",
      "metadata": {
        "id": "470b869b-ed05-4808-9acb-48dc6bf5b6ac"
      },
      "source": [
        "### Carregar Dataset MNIST e Filtrar as imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8c458a1b-85c3-4697-b275-568ae38a0014",
      "metadata": {
        "id": "8c458a1b-85c3-4697-b275-568ae38a0014"
      },
      "outputs": [],
      "source": [
        "# define função para carregar um dígito específico no dataset\n",
        "def load_mnist_digits(digit):\n",
        "    # carrega o Dataset MNIST\n",
        "    (x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Filtrar apenas imagens do dígito desejado\n",
        "    x_train = x_train[y_train == digit]\n",
        "\n",
        "    # Normalizar para o intervalo [-1, 1]\n",
        "    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "    # Expandir dimensões para (28, 28, 1), ou seja, 28x28 grayscale\n",
        "    x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "    return x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91a5052-81cb-4389-87aa-808cdfb26744",
      "metadata": {
        "id": "f91a5052-81cb-4389-87aa-808cdfb26744"
      },
      "source": [
        "#### Carrega apenas o dígito '2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "75935945-d283-4522-b7b2-321540989fa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "75935945-d283-4522-b7b2-321540989fa5",
        "outputId": "b30c6429-b6a4-41a5-9e60-8ae72e8b058f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5958, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset = load_mnist_digits(2)\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a760f72-297f-4780-bdf4-2dffc418fe2c",
      "metadata": {
        "id": "5a760f72-297f-4780-bdf4-2dffc418fe2c"
      },
      "source": [
        "### Define o Modelo GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a67466a8-3f63-4ad6-b4d1-a0af9660771c",
      "metadata": {
        "id": "a67466a8-3f63-4ad6-b4d1-a0af9660771c"
      },
      "source": [
        "#### Cria o Generator (imagens sintéticas a partir de ruídos)\n",
        "```\n",
        "Generator Model\n",
        "-------------------------------------\n",
        "Input: Random Noise (100,)\n",
        "     |\n",
        "Dense Layer (128 neurons, 7x7x128 reshaped)\n",
        "     |\n",
        "Conv2DTranspose Layer (128 filters, kernel=4, stride=2, ReLU)\n",
        "     |\n",
        "Conv2DTranspose Layer (64 filters, kernel=4, stride=2, ReLU)\n",
        "     |\n",
        "Conv2D Layer (1 filter, kernel=7, activation=Tanh)\n",
        "     |\n",
        "Output: Synthesized Image (28x28x1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "76e1529c-b963-4de4-800e-cc59596fd7c3",
      "metadata": {
        "id": "76e1529c-b963-4de4-800e-cc59596fd7c3"
      },
      "outputs": [],
      "source": [
        "def create_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(7 * 7 * 128, input_dim=100),\n",
        "        layers.Reshape((7, 7, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2D(1, kernel_size=7, activation=\"tanh\", padding=\"same\")  # Saída: 28x28, [-1, 1]\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d31c566-b0b7-4bbd-9a11-575ffe20f118",
      "metadata": {
        "id": "6d31c566-b0b7-4bbd-9a11-575ffe20f118"
      },
      "source": [
        "#### Cria o Discriminator (tenta distinguir imagens reais das sintéticas)\n",
        "```\n",
        "Discriminator Model\n",
        "-------------------------------------\n",
        "Input: Image (28x28x1)\n",
        "     |\n",
        "Conv2D Layer (64 filters, kernel=4, stride=2, LeakyReLU)\n",
        "     |\n",
        "Conv2D Layer (128 filters, kernel=4, stride=2, LeakyReLU)\n",
        "     |\n",
        "Flatten Layer\n",
        "     |\n",
        "Dense Layer (1 neuron, Sigmoid activation)\n",
        "     |\n",
        "Output: Probability (Real or Fake)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "553814cc-6918-4c92-a59e-315f6b1b091c",
      "metadata": {
        "id": "553814cc-6918-4c92-a59e-315f6b1b091c"
      },
      "outputs": [],
      "source": [
        "def create_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=(28, 28, 1)),\n",
        "        layers.LeakyReLU(negative_slope=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(negative_slope=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation=\"sigmoid\")  # Saída: probabilidade\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820310a2-b48b-4fa2-b83e-464a3a137983",
      "metadata": {
        "id": "820310a2-b48b-4fa2-b83e-464a3a137983"
      },
      "source": [
        "#### Cria a GAN\n",
        "\n",
        "Na prática a GAN é uma Rede Sequencial com o Generator alimentando o Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2a2527a3-0433-4326-aabc-12049b112ac4",
      "metadata": {
        "id": "2a2527a3-0433-4326-aabc-12049b112ac4"
      },
      "outputs": [],
      "source": [
        "def create_gan(generator, discriminator):\n",
        "    # disciminator não pode ser alterado no modelo (no treinamento ele irá aprender a identificar dados reais)\n",
        "    # discriminator.trainable = False\n",
        "    model = tf.keras.Sequential([generator, discriminator])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7ed8e912-7395-4b42-bcbc-7a4404b784cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "7ed8e912-7395-4b42-bcbc-7a4404b784cb",
        "outputId": "a24818ab-e131-4fc3-b3df-654bff0c30a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_6 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │       \u001b[38;5;34m1,030,017\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sequential_7 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │         \u001b[38;5;34m138,561\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,030,017</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sequential_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">138,561</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,168,578\u001b[0m (4.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,168,578</span> (4.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,168,578\u001b[0m (4.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,168,578</span> (4.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "generator = create_generator()\n",
        "discriminator = create_discriminator()\n",
        "\n",
        "# define o modelo da GAN\n",
        "gan = create_gan(generator,discriminator)\n",
        "gan.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36cc7734-a644-4e72-93e5-fbec05c9c24d",
      "metadata": {
        "id": "36cc7734-a644-4e72-93e5-fbec05c9c24d"
      },
      "source": [
        "### Treinamento da GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "65388773-2215-40a3-94f2-1786023f1792",
      "metadata": {
        "id": "65388773-2215-40a3-94f2-1786023f1792"
      },
      "outputs": [],
      "source": [
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "gen_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)\n",
        "disc_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d2966991-67ac-42db-8412-79122dc372b9",
      "metadata": {
        "id": "d2966991-67ac-42db-8412-79122dc372b9"
      },
      "outputs": [],
      "source": [
        "# @tf.function sinaliza ao TensorFlow que esta é uma função a ser otimizada. Ex.: Usar a GPU\n",
        "@tf.function\n",
        "def train_step(real_images):\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "    # Gerar imagens falsas\n",
        "    random_noise = tf.random.normal([batch_size, 100])\n",
        "    fake_images = generator(random_noise)\n",
        "\n",
        "    # Rótulos para real (1) e fake (0)\n",
        "    real_labels = tf.ones((batch_size, 1))\n",
        "    fake_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    # Treinar o Discriminador\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "        real_predictions = discriminator(real_images)\n",
        "        fake_predictions = discriminator(fake_images)\n",
        "        real_loss = loss_fn(real_labels, real_predictions) # todos labels do real_predictions deveriam ser 1, para 100% de acurácia\n",
        "        fake_loss = loss_fn(fake_labels, fake_predictions) # todos labels do fake_predictions deveriam ser 0, para 100% de acurácia\n",
        "        disc_loss = real_loss + fake_loss\n",
        "    # melhora o Discriminator, ensina ele a identificar imagens ((( !!!!!!! )))\n",
        "    gradients_disc = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    disc_optimizer.apply_gradients(zip(gradients_disc, discriminator.trainable_variables))\n",
        "\n",
        "    # Treinar o Gerador baseado no Discriminator melhorado\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        fake_predictions = discriminator(generator(random_noise))\n",
        "        # neste ponto, treinamos o gerador de forma oposta ao discriminador, ou seja\n",
        "        # quando o discriminador classificar uma imagem Fake como Real, iremos reforçar o\n",
        "        # Gerador de forma positiva.\n",
        "        gen_loss = loss_fn(real_labels, fake_predictions)  # Queremos que o discriminador aceite as imagens geradas\n",
        "    gradients_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gen_optimizer.apply_gradients(zip(gradients_gen, generator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f9219836-fef2-474e-b8ca-4a354c53244a",
      "metadata": {
        "id": "f9219836-fef2-474e-b8ca-4a354c53244a"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs, batch_size=64, sample_interval=10):\n",
        "    # Calcula o número de batches no dataset\n",
        "    num_batches = original_cardinality / batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Itera sobre os batches usando take(num_batches)\n",
        "        for batch_index, real_images in enumerate(dataset.take(num_batches)):\n",
        "            gen_loss, disc_loss = train_step(real_images)\n",
        "\n",
        "            # Mostra o progresso a cada 10% dos batches\n",
        "            #if batch_index % (num_batches // 10) == 0:\n",
        "            #    print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_index+1}/{num_batches}, Gen Loss: {gen_loss.numpy()}, Disc Loss: {disc_loss.numpy()}\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Gen Loss: {gen_loss.numpy()}, Disc Loss: {disc_loss.numpy()}\")\n",
        "\n",
        "        # Salvar imagens geradas\n",
        "        if epoch % sample_interval == 0:\n",
        "            generate_and_save_images(epoch)\n",
        "\n",
        "def generate_and_save_images(epoch, n_samples=16):\n",
        "    random_noise = tf.random.normal([n_samples, 100])\n",
        "    fake_images = generator(random_noise)\n",
        "    fake_images = (fake_images + 1) / 2.0  # Reverter normalização para [0, 1]\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    for i in range(n_samples):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(fake_images[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(f'generated_image_epoch_{epoch}.png')\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f656b7db-2d48-4514-a576-8966054e9448",
      "metadata": {
        "id": "f656b7db-2d48-4514-a576-8966054e9448"
      },
      "source": [
        "#### Iniciar o Treinamento da Rede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7d6642c4-2133-4300-95e5-f8c70007e82f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d6642c4-2133-4300-95e5-f8c70007e82f",
        "outputId": "9a2187e9-7f2c-487a-936c-be69d7d21862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Gen Loss: 0.7168847918510437, Disc Loss: 1.3899824619293213\n",
            "Epoch 2/10, Gen Loss: 0.723505973815918, Disc Loss: 1.37626314163208\n",
            "Epoch 3/10, Gen Loss: 0.7032522559165955, Disc Loss: 1.3739572763442993\n",
            "Epoch 4/10, Gen Loss: 0.7121347784996033, Disc Loss: 1.3695752620697021\n",
            "Epoch 5/10, Gen Loss: 0.6963053345680237, Disc Loss: 1.3845758438110352\n",
            "Epoch 6/10, Gen Loss: 0.7185802459716797, Disc Loss: 1.380622148513794\n",
            "Epoch 7/10, Gen Loss: 0.730782151222229, Disc Loss: 1.366746425628662\n",
            "Epoch 8/10, Gen Loss: 0.7077147364616394, Disc Loss: 1.4024338722229004\n",
            "Epoch 9/10, Gen Loss: 0.7309221625328064, Disc Loss: 1.361374855041504\n",
            "Epoch 10/10, Gen Loss: 0.715548574924469, Disc Loss: 1.3650388717651367\n"
          ]
        }
      ],
      "source": [
        "# Embaralhar o dataset\n",
        "dataset_tf = tf.data.Dataset.from_tensor_slices(dataset)\n",
        "\n",
        "# Embaralhar o dataset\n",
        "original_cardinality = dataset_tf.cardinality().numpy()\n",
        "\n",
        "dataset_tf = dataset_tf.shuffle(original_cardinality).batch(64)\n",
        "\n",
        "# Treinar por 100 épocas\n",
        "train(dataset_tf, epochs=10, sample_interval=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando a GAN para criar dígitos"
      ],
      "metadata": {
        "id": "rHvODM_7Gyab"
      },
      "id": "rHvODM_7Gyab"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "113c5b5d-ace5-4b4f-9c0c-bfe6f0a725e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "113c5b5d-ace5-4b4f-9c0c-bfe6f0a725e5",
        "outputId": "96b40c1d-6efc-42a7-da87-c7c30b033cc5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAD7pJREFUeJztXFtvG1UXXeO5z9gzYzuJc2vaJm0TKJc+VeJWCSSQgAfe+gP4jTwgVeKlAglQCw0lbVWSktDEsR3f5ua5z/dQnVM7TagLsT3085Kipk7iy1ln77P32nsfJk3TFFNMFLlJv4EppiRkAlMSMoApCRnAlIQMYEpCBjAlIQOYkpABTEnIALhhf5FhmFG+j9cSw4oRU0vIAKYkZABTEjKAoc+ESYFhGDAMg1wuB47jwDAMkiRBFEVI05R+/ZeRKRJyuWeGSRaeZVnk83nIsgzDMHD58mVomoZqtYrt7W30ej1YlgXbtv/TRGSGBLLbgWdk5HI5CIKAUqkEwzCwsrKCTz/9FMvLy7h37x6iKEK73UaapnAcZ0rCPwVZ+FwuB0VRYBgGOI6jj/E8j7m5OWiahvn5eZTLZRiGgZmZGSwtLUFRFLAsC47jEIYhTNNEr9cDMHx4mAUww1bWRpEnCIKAQqEAURRx7do1fPbZZzAMAyzLgmVZ5HI5yLIMQRCgqioWFxehqira7Taq1So8z8PR0RGazSaazSZu3bqFzc1NxHFMz4xJYtjXn6glsCwLVVWhKAo2Njbw5ZdfYmFhge5uQvzxfyuVCjY2NpAkCdrtNtrtNvb39/Ho0SNsbW2BYRjEcTxxEobFxEhgGAayLGN5eRmlUgnz8/OQJIlaAVnwKIoQxzHiOEav10Mcx5AkCYVCAQzDgOd5yLIMXdexsbGBTqcD27ZxcHAAx3Hg+z5c10WSJJP6qC/FRNwRiX4uX76MmzdvYm1tDaurq3j33Xehqip9rTiO0e12aRS0t7cHx3GwvLyMN954A7IsI0kSJEmCIAhQrVbRbrexu7uLb7/9Fnt7e6jVatjZ2YHneWf2/odF5t0RwzCQJAlLS0tYW1vD3NwcBEGgERKJ/4MggOu6sCwLjUYDpmkin89Tn08OcmIdaZpC13X89ttvcBwHjuPQ58wqxk4CwzDgOA4sy0IURSiKAlVVIQgCGIZBmqbwPA++78OyLPz666948uQJgiCAZVkIwxCapqHT6SBJEsiyDFmWB84NnuehaRpKpRKazeaUhBNflOMgCAJkWUahUICu61AUhWbDtm2j1WqhVqvhm2++we3btyHLMubm5qAoCmRZxqVLlxAEAcrlMiRJoi4OAERRxMzMDHq9HhqNBliWncTHHBoTsQSSB+RyObp4cRwjCAIAgOM4ME0T7XYbjUYDh4eHUFUVoigiSRJYloVutwuWZaEoCqIooiEteX5JkqAoCrWwLGMiJPA8D0mSAADNZhP7+/vwfR+e5yEIAuzs7GBnZwfdbhePHj2C53lIkgT7+/sQBIHucE3TcP36dVy/fh2yLKNYLNKQ98KFC9A0DbVabcDVZRETJSFNU0pCo9HAX3/9Bdu2sbm5ic3NTQRBgDAMEccxfN+HbdtgGAZ7e3u4c+cOZFmG7/uYm5uDYRgQRXGAhEqlgsePHw9YQxaJGDsJaZpSFTQIApimiVarRZMu27ZhWRZc10UURQN/RxYwjmOEYYg0TdHpdFCr1ej5oGkaoigCx3GQJAmqqsIwDPR6PfR6PbiuO+6P/FKMnYQkSWgSxTAM7ty5Q11Po9GA7/uo1WpDJVdRFGFzcxOu62J2dhaff/450jSFIAjI5/NQFAVra2v4+OOPUa/XsbW1ha2tLcRxPIZPOjwmYgme51H3sL29DVVV4TgOut0uoihCr9cbmoTd3V3UajXMz89jfX0dKysrKBQKMAwDiqJgfn4eb731Fo6OjtBqtfDo0aMpCQRpmlIpghATBAGVKIYFEeuiKEKSJC8UeURRRLFYRJIkNAzOGiYq4Pm+j0ajgVwuhyRJqOj2KjoP0ZZ6vd4LyinDMCgWi1hfX0en08Hdu3epLpWlA3qiJCRJ8q81HULYaZYgCAJ0XaeC4dQSRog0TanQx3EcdWnE7RGLyZIFELw2JMRxTOUOlmVpeJskCcIwpPlGFhsDsq1svQLSNIXv+3AcZ+joKit4bSzB8zw8ePAAvV4PV65cwcbGBmZnZyGKIkqlEjiOm0ZHowYhYXd3F67r4osvvgDwLEQVBAE8z0NRFCryZcklvTYkkAJQLpeD7/sDh3AulwPLstA0DQsLC1SFJZ0Zk8ZrRYLv+4iiCI7j0MIQy7LgeR6CIOD69esAgHq9jlu3buHevXsTftfP8FqRQKIg3/cRhiGiKKJnAMdxtIPv6dOnuH//fmZIyER0dNaHJbEG4nKSJAHDMLR/SVVVyLIMURTB8/zED+uJW0J/6ZGElf/20PQ8DwcHBygWi6hUKlAUBaIo0kazOI4xMzODYrFI6xRhGP6r1/w3mHgbJPlK03RgR/4bIuI4piVS0oEBADzPg+d5qKoKSZIgCAK1kklibCT0d1qTRWBZFoIgUFEtl8vRKCcIAkoMwzAD3RYvE/ls28bW1hYsy0IQBLh48SJtBjheGMqClDE2EkhhXxRFVCoVlMtl8DyPfD4PnudpBwYAmKYJy7KQpin9O9M0sbu7C8uyXio/tFotfP/998jn80iSBO+99x50XQfw/PzpP8AnnV2PnASyk0nSJEkSdF2HYRi0IZi4CUICx3HgOG6AhFwuh1arhTRNaWmUWARRT8n3URTBNE0EQQDHcU50OeT3J20FwIhJkCQJ+XwekiTh6tWruHr1KhRFwdzcHHRdpw1gpF2FHNIkxickMAwDx3FQrVbhui5s20an06Ht8KZp0sO41WpRFTUIghO7s/v//39BAim+f/TRR/jqq6+gqio0TXtBx3nZoez7PrrdLnzfR7PZxMHBAXq9Hvb393FwcADTNGloyjAMXfz+ZoF+ZGnUamQkMAwDRVFQqVToYEehUICiKFAUhR6UwyKXyyGKIgiCQOvQpOUliiLa4U3qCMQNFovFFzrw+ufgstAieeYk9H+49fV13Lx5E5VKBaurq1TN5Hn+lZ+XRFVJkkAURWiahjiOcfHiRbiuiyAI8P7778M0TVrIAYDV1VUUCoUX3iM5nxiGoVrTpDASSyD+fXFxER988AGWl5chSRLtugNePUsmkRUAOkgIPHddxPXEcUwLOaT9RZblF56PaEpxHL9+eQLHcdA0jWaoREY+bvb9Prk/HwBOJuikx44neP2Dh+Tn/QMn/b9HZuRs24Zt27QPdhI4cxIURcHq6ioMw8D58+epVNBPAll4smOTJBmYU/4nvpokgizL0rkF8vhxEnieR6VSwaVLl3B0dIROpzPRzryRWEKhUECpVBpIxI6DEEH6jDiOo/F8f2Y7bA/pSYt9Gogl6LoOz/Mm3jo/soP5tEUhC0/6jIgfd12XzpZJkkTzB6Lx9D8/2fX/FCzLolwu49y5cwCehdJEMplEyDqSg7nfpZyUqZLdH0UR1f1JV3YQBNB1Hbqu02FyMiRIvvrd1j+BIAg0nOU4Dvl8HizL0o0xbow0Wfu7XUV2HWlh9DwPpmnSRmEidZA5ZrL7+4s0xw/mYUHm5QqFAh3VIln2JKSMMyeBqKCe550oGfRfFuJ5Hur1Omzbxu7uLu7fv49erwdBEGhoubKygtnZWXAcB1mWwXEcrROQxTvpzPk7cByHmZkZ8DwPz/OwurqKKIrQ6XRQr9fHXls4cxJIxPN3CiVxU2EYolarodls4o8//sD9+/dh2zbdkbIsY319HUtLSxBFEbquQxRFLC0t0QSMuKdXASHBMAx4nocLFy4gDEM8ffoUrVbr9SChf/SJKJsn6UTk/gqy84maSlwNOaDJY/3XLfydGzpNsOvPQ4g1En3LNE3Ytg2e56l4OC63dOYkeJ6HarVKJ2hI5wNxG/1Rk6IoOHfuHMrlMhiGgWVZcByHZteSJGF5eRnlcnmgAFQqlagrOu1w7u9FJYtJCOz/fn5+Hp988gk6nQ5u376Nvb096lJ93z/r5TkRZ05CGIZot9uwLAudToe6peOLRQ7emZkZhGEI13VxeHgI13WhaRo0TYMgCFT27ievUChQAk4Lg/sTwn5LOJ5V67qOt99+G2EYol6vo1AowDTNsUZJI4mOSKjneR663S6Vr/sXrj/cBJ4t7Pz8PHzfp8N/ZCicyN79c8rH3RI5i0ik1Wq1qDBHNsHs7CxmZ2cH7s/ozzkKhQKWlpaQy+VweHhIp0ZHjZEdzHEco9VqYXt7G47j4Pz581AUBcDzDguWZSHLMtI0xfnz51Eul5EkycAikbMAeO7TifjWT0wcx/RykXq9jp9++gn1ep02CXMchxs3buDDDz8cmHEml1ulaYqVlRXcuHED9XodP/74I46Ojv6bJADPW1eIJciyTG9oIZnp8V2Yz+eRz+cHnue0w/G0UiW50YVcMrK/v0/vxeB5HleuXIHneQOKLPDcNRUKBSwsLFALHJe6OrJkLU1TtNttPHz4EPV6nRIgyzLK5fILWfBJOE03Ihk3mQQl7fB7e3s4OjpCtVrFzs4OqtUqwjBEr9cDy7L4+eefEUURDMPAtWvXcOHCBZp/sCxLS6Jkdm5cGCkJh4eH+OGHH5DP52n7iaZpePPNN6lf779caliQyloYhrS8ads2Hjx4QAfTf/nlFzSbTWolDMOgWq3iu+++w8LCAr7++mt6TwZxeeR5Xdel9YhxYKSyRRAE6Ha7CMMQrVYLrVaLXiBC1Eue5wf6joBBRbR/Do1873keHMehz99qteiUTrPZpEPpx+Xp/tFd8jsAXiiJjrvkOVISfN9Hu92G4zj4/fff0el06H0TKysrEASBhqKKotDQU5ZlWoUjNWTP89But+H7Pur1OnZ3d9Hr9XB4eIharUYf73a7cF331IFEMtv24MEDyLKMxcVFWvvO5/NYWVmBqqooFotjI2PkJARBAIZh0O128fjxY6iqSkkg1+fIsoxSqYTFxUWIogjDMGAYBr1uk4h7f/75JyzLwvb2Nu7evQvLsuiVDCQs7u9BOg2e5+Hhw4ewbRsbGxt45513UKlUoKoqzp07R4fR//MHMwFxJcTHsiwL0zTRbDbpSKskSbS8KIoiHMehHXiu69ILqGq1GmzbRrPZpDID+fmrqJ9JksB1XXS7XXqdj67raDabqNVqME1zrHetjq0NknTGOY6DJ0+eoFarUe2GNIGRKIVoSQCoCEi66cIwpBYQhiHVp15lwcIwRLVaRbfbhWmatNzZaDTouNXOzs6pPUtnjYneizrM641yNzIMA13Xsba2Rs+qJ0+ewPO8M3ndYZ9j4vMJp2EcroAUlSzLojnHJLq0M2sJ4wKpY7MsizAMz8wKgOE30v89CaPEsCRMvhFziikJWcCUhAxgSkIGMCUhA5iSkAFMScgApiRkAFMSMoChtaMsTDm+rphaQgYwJSEDmJKQAUxJyACmJGQAUxIygCkJGcCUhAxgSkIG8D/J6+n1Je0VbQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Gera e mostra um número criado sintéticamente\n",
        "random_noise = tf.random.normal([1, 100]) # novo vetor de ruído\n",
        "generated_image = generator(random_noise)\n",
        "generated_image = (generated_image + 1) / 2.0  # Reverte a normalização\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(1, 1))\n",
        "\n",
        "ax.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}